{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Ray Image Classification of Pneumonia in Pediatric Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/title image.jpeg\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project explores a dataset of x-ray images from pediatric patients with/without pneumonia. Pneumonia is a very common inflammatory condition that is found in the lungs, primarily in the air sacs when filled with fluid or pus. Symptoms can include cough, fever, chills, and difficulty breathing. Pneumonia can be life-threatening, but particularly to infants, children and people over the age of 65 ([Mayo Clinic](https://www.mayoclinic.org/diseases-conditions/pneumonia/symptoms-causes/syc-20354204)). \n",
    "\n",
    "The images in the dataset were selected from cohorts of patients from one to five years old from Guangzhou Women and Children's Medical Center. The data was provided by Kermany et al. on Mendeley through [Kaggle datasets](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia). All the chest x-ray images were screened for quality control, and then the diagnoses of the images were graded by two expert physicians before cleared for training. With the implementation of neural network models, it can help classify whether or not a given patient has pneumonia, given a chest x-ray image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "The Children's Medical Center has asked for assistance in partially automating the diagnosis of pneumonia in their pediatric patients. Rather than finding the best possible accuracy on a model, a deep neural network that has been clearly iterated on can help our understanding of how these models and automation work in order to help doctors confidently and efficiently diagnosis pneumonia. Broadly speaking, this can also help our understanding of AI learning and its implementation in other parts of the medical field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "The data was organized into three folders: train, test, and val. Each folder contains sub-folders labeled as two categories, normal and pneumonia. Within the train set there are 5216 images between the two classes, 624 in test and only 16 images in val. Since the val set contained very few images, to better balance the validation set, I randomly selected images from the test folder and moved them to the respective class within val. The data_split notebook linked in this repository outlines this process. With the data augmentation, the redistribution of the test images into the validation set can be seen in the output as well.\n",
    "\n",
    "Since the goal of this analysis is not to build the best model possible, but rather demonstrate an understanding of a working model. With the dataset being quite large, only training on a portion of the dataset will allow me to run models in a reasonable time first before training on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.random as tfr\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating path to the respective folder for each set in the data structure\n",
    "data_path = os.path.join('chest-xray-pneumonia', 'chest_xray')\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "val_path = os.path.join(data_path, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chest-xray-pneumonia/chest_xray/train'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking path\n",
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the data images (https://www.kaggle.com/paramarthasengupta/pneumonia-diagnosis-eda-and-prediction?scriptVersionId=76497874&cellId=7)\n",
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "\n",
    "def get_data(data_dir):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the 3 datasets\n",
    "train = get_data(train_path)\n",
    "test = get_data(test_path)\n",
    "val = get_data(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing data distribution in train set, first creating a dataframe to help plot\n",
    "train_df = pd.DataFrame(train, columns=['image', 'label'])\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "sns.countplot(train_df['label'], palette = 'coolwarm')\n",
    "plt.title('Train Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data appears imbalanced, with many more instances of pneumonia compared to normal. Data augmentation will help balance the distribution, this will be done in the data preparation section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#sample image to see what the x-rays look like to begin with\n",
    "plt.figure(figsize= (8, 8))\n",
    "plt.imshow(train[0][0], cmap='gray')\n",
    "plt.title(labels[train[0][1]]);\n",
    "\n",
    "plt.figure(figsize= (8, 8))\n",
    "plt.imshow(train[-1][0], cmap='gray')\n",
    "plt.title(labels[train[-1][1]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The 3 datasets are split into train, test splits. Following this, image normalization and reshaping is done so that the images can be more easily interpreted once trained on a model. As previously mentioned, data augmentation is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into X_train, y_train, etc.\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for feature, label in train:\n",
    "    X_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "    X_test.append(feature)\n",
    "    y_test.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    X_val.append(feature)\n",
    "    y_val.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since these images are x-rays, they are a little more complex than simple images which is better suited for MLP\n",
    "#cnn is probably better suited after a baseline model\n",
    "#cnn takes 4-D tensors as input, which is what we have\n",
    "#first, must normalize image data (since all pixel values will always be between 0 and 255)\n",
    "X_train = np.array(X_train) / 255\n",
    "X_val = np.array(X_val) / 255\n",
    "X_test = np.array(X_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = X_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of X_train array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 511 images belonging to 2 classes.\n",
      "Found 129 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#data augmentation, applies random transformations on each image as it is passed to the model\n",
    "#makes model more robust and saves on memory\n",
    "#also prevents overfitting and handling imbalance in dataset\n",
    "#instatiate ImageDataGenerator for data augmentation and then pass through each path to the 3 datasets\n",
    "#https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1/)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(200, 200),\n",
    "                                        color_mode='grayscale',\n",
    "                                        shuffle=True,\n",
    "                                        seed=42,\n",
    "                                        class_mode='binary',\n",
    "                                        batch_size=32)\n",
    "test_gen = datagen.flow_from_directory(test_path,\n",
    "                                       target_size=(200, 200),\n",
    "                                       color_mode='grayscale',\n",
    "                                       shuffle=False,\n",
    "                                       seed=42,\n",
    "                                       class_mode=None,\n",
    "                                       batch_size=1)\n",
    "val_gen = datagen.flow_from_directory(val_path,\n",
    "                                      target_size=(200, 200),\n",
    "                                      color_mode='grayscale',\n",
    "                                      shuffle=True,\n",
    "                                      seed=42,\n",
    "                                      class_mode='binary',\n",
    "                                      batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "#                                    samplewise_center=True,\n",
    "#                                    samplewise_std_normalization=True,\n",
    "#                                    rotation_range=15,\n",
    "#                                    width_shift_range=0.2,\n",
    "#                                    height_shift_range=0.2,\n",
    "#                                    shear_range=0.2,\n",
    "#                                    zoom_range=0.2,\n",
    "#                                    horizontal_flip=True)\n",
    "# test_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "#                                   featurewise_center=True,\n",
    "#                                   featurewise_std_normalization=True)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(train_path,\n",
    "#                                                     target_size=(150, 150),\n",
    "#                                                     batch_size=32,\n",
    "#                                                     class_mode='binary')\n",
    "# test_generator = test_datagen.flow_from_directory(test_path,\n",
    "#                                                   target_size=(150, 150),\n",
    "#                                                   batch_size=32,\n",
    "#                                                   class_mode='binary')\n",
    "# val_generator = test_datagen.flow_from_directory(val_path,\n",
    "#                                                  target_size=(150, 150),\n",
    "#                                                  batch_size=32,\n",
    "#                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #displaying random images to see how they look after creating the generators\n",
    "# print('Display Random Images')\n",
    "\n",
    "# # Adjust the size of your images\n",
    "# plt.figure(figsize=(20,10))\n",
    "\n",
    "# for i in range(12):\n",
    "#     num = rn.randint(1,30)\n",
    "#     plt.subplot(3,4, i + 1)\n",
    "    \n",
    "#     x,y = train_generator.__getitem__(num)\n",
    "    \n",
    "#     plt.imshow(x[num],cmap='gray')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "# # Adjust subplot parameters to give specified padding\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualize examples from the train dataset #need to add label\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking the shape/format of our input\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #since this is currently a list, change to arrays\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# X_test = np.array(X_test)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# X_val = np.array(X_val)\n",
    "# y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train Shape:', X_train.shape)\n",
    "# print('Test Shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(featurewise_center=False,\n",
    "#                              featurewise_std_normalization=False,\n",
    "#                              rotation_range=20,\n",
    "#                              width_shift_range=0.2,\n",
    "#                              height_shift_range=0.2,\n",
    "#                              horizontal_flip=True)\n",
    "# datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline model (helpful code from Joél study group)\n",
    "def baseline_model():\n",
    "    layers = [\n",
    "        Input(shape=(200,200,1)),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    "    model = Sequential(layers)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', #gradient descent, moving average\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the model and pass in 1 of the train images to set the shape of input images\n",
    "model_1 = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               4000100   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 4,000,201\n",
      "Trainable params: 4,000,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/163 [==============================] - 36s 218ms/step - loss: 138.5949 - accuracy: 0.7140 - val_loss: 0.6822 - val_accuracy: 0.6172\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 37s 225ms/step - loss: 0.6551 - accuracy: 0.7429 - val_loss: 0.6723 - val_accuracy: 0.6172\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 40s 245ms/step - loss: 0.6315 - accuracy: 0.7429 - val_loss: 0.6643 - val_accuracy: 0.6250\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 42s 258ms/step - loss: 0.6136 - accuracy: 0.7429 - val_loss: 0.6618 - val_accuracy: 0.6250\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 38s 235ms/step - loss: 0.6002 - accuracy: 0.7429 - val_loss: 0.6620 - val_accuracy: 0.6250\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 40s 243ms/step - loss: 0.5906 - accuracy: 0.7429 - val_loss: 0.6691 - val_accuracy: 0.6172\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 38s 232ms/step - loss: 0.5838 - accuracy: 0.7429 - val_loss: 0.6671 - val_accuracy: 0.6250\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 38s 232ms/step - loss: 0.5790 - accuracy: 0.7429 - val_loss: 0.6769 - val_accuracy: 0.6172\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 39s 237ms/step - loss: 0.5758 - accuracy: 0.7429 - val_loss: 0.6810 - val_accuracy: 0.6172\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 40s 243ms/step - loss: 0.5736 - accuracy: 0.7429 - val_loss: 0.6852 - val_accuracy: 0.6172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5f4f05a00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train = train_gen.n // train_gen.batch_size\n",
    "step_size_val = val_gen.n // val_gen.batch_size\n",
    "model_1.fit_generator(train_gen,\n",
    "                      validation_data=val_gen,\n",
    "                      epochs=10,\n",
    "                      steps_per_epoch=step_size_train,\n",
    "                      validation_steps=step_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#evaluating model performance\n",
    "score = model_1.evaluate_generator(test_gen)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6825205087661743\n",
      "Test accuracy: 0.6201550364494324\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate_generator(val_gen)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = Sequential()\n",
    "# model_1.add(Dense(64, activation='relu', input_shape=(150, 150, 1)))\n",
    "# model_1.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_1.fit_generator(train_it, steps_per_epoch=16, validation_data=val_it, validation_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.fit(train_generator, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fit the model\n",
    "# base = model_1.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "#                    epochs=10,\n",
    "#                    validation_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Convolutional Neural Network (CNN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1():\n",
    "    layers = [\n",
    "        Input(shape=(200,200,1)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    "    model = Sequential(layers)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = conv_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 313632)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               40145024  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 40,145,473\n",
      "Trainable params: 40,145,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/163 [==============================] - 76s 465ms/step - loss: 144.2521 - accuracy: 0.8614 - val_loss: 15.9288 - val_accuracy: 0.7188\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 94s 575ms/step - loss: 1.0335 - accuracy: 0.9559 - val_loss: 6.3443 - val_accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 87s 530ms/step - loss: 0.3967 - accuracy: 0.9753 - val_loss: 9.8293 - val_accuracy: 0.7969\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 89s 543ms/step - loss: 0.2645 - accuracy: 0.9822 - val_loss: 14.4991 - val_accuracy: 0.7266\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 89s 546ms/step - loss: 0.2347 - accuracy: 0.9837 - val_loss: 21.1264 - val_accuracy: 0.7031\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 98s 603ms/step - loss: 0.1600 - accuracy: 0.9883 - val_loss: 18.0933 - val_accuracy: 0.7188\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 104s 638ms/step - loss: 0.0606 - accuracy: 0.9950 - val_loss: 21.6365 - val_accuracy: 0.6797\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 97s 592ms/step - loss: 0.0443 - accuracy: 0.9954 - val_loss: 15.1439 - val_accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 95s 580ms/step - loss: 1.7144 - accuracy: 0.9682 - val_loss: 13.7883 - val_accuracy: 0.7344\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 96s 587ms/step - loss: 0.3203 - accuracy: 0.9762 - val_loss: 10.4076 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5f25b91f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit_generator(train_gen,\n",
    "                      validation_data=val_gen,\n",
    "                      epochs=10,\n",
    "                      steps_per_epoch=step_size_train,\n",
    "                      validation_steps=step_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate_generator(test_gen)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 10.3269681930542\n",
      "Test accuracy: 0.7674418687820435\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate_generator(val_gen)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2():\n",
    "    layers = [\n",
    "        Input(shape=(200,200,1)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    "    model = Sequential(layers)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = conv_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
